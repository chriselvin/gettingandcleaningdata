xpathSApply(rootNode,"//name",xmlValue)
xpathSApply(rootNode,"//price", xmlValue)
fileURL = "http://espn.go.com/nfl/team/_/name/baltimore-ravens"
doc <- htmlTreeParse(fileURL,useInternal = TRUE)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue)
teams <- xpathSApply(doc,"//li[@class='team-name", xmlValue)
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL, destfile = "./data/ACS.csv", method = "curl")
DT = read.table("./data/ACS.csv", sep = ",", header = TRUE)
tapply(DT$pwgtp15,DT$SEX,mean)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT$pwgtp15,by=DT$SEX)
sapply(split(DT$pwgtp15,DT$SEX),mean)
if(!file.exists("data")){dir.create("data")}
fileURL <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(fileURL, destfile = "./data/cameras.csv", method = "curl")
dateDownloaded = date()
dateDownloaded
cameras <- read.table("./data/cameras.csv", sep=",", header = TRUE)
head(cameras)
install.packages("jsonlite")
library(jsonlite)
jsonData <- fromJSON("https://api.github.com/users/chriselvin/repos")
names(jsonData)
names(jsonData$owner)
jsonData$owner$login
myjson <- toJSON(iris,pretty=TRUE)
cat(myjson)
iris2 <- fromJSON(myjson)
head(iris2)
con = url("http://eflclub.com")
htmlCode = readLines(con)
close(con)
htmlCode[1:4]
library(XML)
url <- "http://www.eflclub.com"
html <- htmlTreeParse(url, useInternalNodes=T)
xpathSApply(html,"//title", xmlValue)
library(httr)
google = handle("http://google.com")
pg1 = GET(handle=google, path ="/")
pg2 = GET(handle = google, path = "search")
library(RmySQL)
library(sqldf)
if(!file.exists("data"){dir.create("data")})
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL, destfile = "./data/ACS.csv", method = "curl")
dateDownloaded = date()
dateDownloaded
str(ACS)
summary(ACS)
sqldf("select * from ACS where AGEP <50")
fileURL = "http://biostat.jhsph.edu/~jleek/contact.html"
download.file(fileURL, destfile="./data/jleek.html", method = "curl")
dateDownloaded = date()
dateDownloaded
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
nchar(htmlCode[c(10,20,30,100)])
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(fileURL, destfile = "./data/what.for", method = "curl")
dateDownloaded = date()
dateDownloaded
set.seed(13435)
X <- data.frame("var1"=sample(1:5), "var2"= sample(6:10), "var3"=sample(11:15))
X <- X[1:5,]; X$var2[c(1,3)] = NA
X
X[,1]
X[,"var1"]
X[1:2,"var2"]
X[which(X$var2>8),]
sort(X$var1, decreasing = TRUE)
sort(X$var2, na.last = TRUE)
X[order(X$var1),]
X[order(X$var1, X$var3),]
library(plyr)
arrange(X,var1)
arrange(X,desc(var1))
X$var4 <- rnorm(5)
X
Y <- cbind(X,rnorm(5))
Y
if(!file.exists("data")){dir.create("data")}
fileURL <- "https://data.baltimorecity.gov.api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL, destfile = "./data/baltimorerestaurants.csv", method = "curl")
dateDownloaded <- date()
dateDownloaded
restData <- read.csv("./data/baltimorerestaurants.csv", header = TRUE)
s1 <- seq(1,10,by=2) ; s1
s2 <- seq(1,10, len=3); s2
x <- c(1,3,8,25,100) ; seq(along = x)
library(reshape2)
head(mtcars)
mtcars$carname <- rownames(mtcars)
carMelt <- melt(mtcars, id=c("carname","gear","cyl"), measure.vars=c("mpg","hp"))
head(carMelt, n = 3)
cylData <- dcast(carMelt, cyl ~ variable)
cylData
cylData <- dcast(carMelt, cyl ~ variable, mean)
cylData
head(InsectSprays)
tapply(InsectSprays$count,InsectSprays$spray, sum)
agricultureLogical <- acs$ACR == 3 & acs$AGS == 6
ACS[which(agricultureLogical == TRUE),]
library(jpeg)
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileURL, destfile = "./data/jeff.jpeg", method = "curl")
dateDownloaded = date()
jeff <- readJPEG("./data/jeff.jpeg", native = TRUE)
quantile(jeff, probs = c(0.3,0.8))
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileURL, destfile = "./data/FGDP.csv", method = "curl")
FGDP <- read.csv("./data/FGDP.csv", header = TRUE, stringsAsFactors=FALSE)
head(FGDP)
str(FGDP)
FGDP <- FGDP[5:194,c(1,2,4,5)]
colnames(FGDP)[colnames(FGDP)=="X"] <- "countryCode"
colnames(FGDP)[colnames(FGDP)=="Gross.domestic.product.2012"] <- "gdpRank"
colnames(FGDP)[colnames(FGDP)=="X.2"] <- "countryName"
colnames(FGDP)[colnames(FGDP)=="X.3"] <- "gdpMillions"
FGDP$gdpRank <- as.numeric(FGDP$gdpRank)
str(FGDP)
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileURL, destfile = "./data/Country.csv", method = "curl")
Country <- read.csv("./data/Country.csv", header = TRUE, stringsAsFactors=FALSE)
head(Country)
str(Country)
mergedData = merge(FGDP, Country, by.x="countryCode", by.y="CountryCode", all=FALSE)
head(mergedData)
summary(mergedData)
str(mergedData)
ordered <- mergedData[order(mergedData$gdpRank),]
# I lost a country somehow. St. Kitts is the 12th in my data.
ordered[178,]
sub(",","", mergedData$gdpMillions)
mergedData$gdpMillions <- sub(",","", mergedData$gdpMillions)
str(mergedData)
mergedData$gdpMillions <- as.numeric(mergedData$gdpMillions)
str(mergedData)
highincomeOECD <- subset(mergedData, mergedData$Income.Group == "High income: OECD")
mean(highincomeOECD$gdpRank)
highincomenonOECD <- subset(mergedData, mergedData$Income.Group == "High income: nonOECD")
mean(highincomenonOECD$gdpRank)
GDPgroups = cut(GDPgroups, quantile)
View(mergedData)
View(mergedData)
GDPgroups = cut(mergedData$gdpRank, breaks = quantile(mergedData$gdpRank))
table(GDPgroups)
View(mergedData)
table(GDPgroups, Income.Group)
table(GDPgroups, mergedData$Income.Group)
GDPgroups = cut(mergedData$gdpRank, breaks = quantile(mergedData$gdpRank, probs=c(0.2,0.4,0.6,0.8)))
table(GDPgroups, mergedData$Income.Group)
GDPgroups = cut(mergedData$gdpRank, breaks = quantile(mergedData$gdpRank))
table(GDPgroups, mergedData$Income.Group)
table(mergedData$Income.Group, GDPgroups)
GDPgroups = cut(mergedData$gdpRank, breaks = quantile(mergedData$gdpRank))
table(mergedData$Income.Group, GDPgroups)
library(Hmisc)
GDPgroups = cut2(mergedData$gdpRank, g=5))
table(mergedData$Income.Group, GDPgroups)
library(Hmisc)
GDPgroups = cut2(mergedData$gdpRank, g=5)
table(mergedData$Income.Group, GDPgroups)
if(!file.exists("./data"){dir.create("./data")}
fileURL <- "https://data.baltimorecity.gov/api/views/dz54-2ru/rows.csv?accessType=DOWNLOAD"
download.file(fileURL, destfile = "./data/cameras.csv", method = "curl")
cameraData <- read.csv("./data/camera.csv")
names(cameraData)
cameraData <- read.csv("./data/cameras.csv")
names(cameraData)
View(cameras)
View(cameraData)
cameras <- read.csv("./data/cameras.csv")
if(!file.exists("data")){dir.create("data")}
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileURL, destfile = "./data/acs.csv", method = "curl")
dateDownloaded <- date()
dateDownloaded
list.files("./data")
acs = read.table("./data/acs.csv", sep =",", header = TRUE)
table(acs$VAL==24)
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileURL, destfile = "./data/dat.xlsx", method = "curl")
dateDownloaded <- date()
dateDownloaded
library(xlsx)
colIndex = 7:15
rowIndex = 18:23
dat <- read.xlsx("./data/dat.xlsx", sheetIndex = 1, colIndex = colIndex, rowIndex = rowIndex)
sum(dat$Zip*dat$Ext, na.rm = T)
library(XML)
fileURL = "http://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileURL, useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]][[1]]
xmlSApply(rootNode,xmlValue)
xpathSApply(rootNode,"//name",xmlValue)
xpathSApply(rootNode,"//price", xmlValue)
fileURL = "http://espn.go.com/nfl/team/_/name/baltimore-ravens"
doc <- htmlTreeParse(fileURL,useInternal = TRUE)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue)
teams <- xpathSApply(doc,"//li[@class='team-name", xmlValue)
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL, destfile = "./data/ACS.csv", method = "curl")
DT = read.table("./data/ACS.csv", sep = ",", header = TRUE)
tapply(DT$pwgtp15,DT$SEX,mean)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT$pwgtp15,by=DT$SEX)
sapply(split(DT$pwgtp15,DT$SEX),mean)
if(!file.exists("data")){dir.create("data")}
fileURL <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(fileURL, destfile = "./data/cameras.csv", method = "curl")
dateDownloaded = date()
dateDownloaded
cameras <- read.table("./data/cameras.csv", sep=",", header = TRUE)
head(cameras)
install.packages("jsonlite")
library(jsonlite)
jsonData <- fromJSON("https://api.github.com/users/chriselvin/repos")
names(jsonData)
names(jsonData$owner)
jsonData$owner$login
myjson <- toJSON(iris,pretty=TRUE)
cat(myjson)
iris2 <- fromJSON(myjson)
head(iris2)
con = url("http://eflclub.com")
htmlCode = readLines(con)
close(con)
htmlCode[1:4]
library(XML)
url <- "http://www.eflclub.com"
html <- htmlTreeParse(url, useInternalNodes=T)
xpathSApply(html,"//title", xmlValue)
library(httr)
google = handle("http://google.com")
pg1 = GET(handle=google, path ="/")
pg2 = GET(handle = google, path = "search")
library(RmySQL)
library(sqldf)
if(!file.exists("data"){dir.create("data")})
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL, destfile = "./data/ACS.csv", method = "curl")
dateDownloaded = date()
dateDownloaded
str(ACS)
summary(ACS)
sqldf("select * from ACS where AGEP <50")
fileURL = "http://biostat.jhsph.edu/~jleek/contact.html"
download.file(fileURL, destfile="./data/jleek.html", method = "curl")
dateDownloaded = date()
dateDownloaded
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
nchar(htmlCode[c(10,20,30,100)])
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(fileURL, destfile = "./data/what.for", method = "curl")
dateDownloaded = date()
dateDownloaded
set.seed(13435)
X <- data.frame("var1"=sample(1:5), "var2"= sample(6:10), "var3"=sample(11:15))
X <- X[1:5,]; X$var2[c(1,3)] = NA
X
X[,1]
X[,"var1"]
X[1:2,"var2"]
X[which(X$var2>8),]
sort(X$var1, decreasing = TRUE)
sort(X$var2, na.last = TRUE)
X[order(X$var1),]
X[order(X$var1, X$var3),]
library(plyr)
arrange(X,var1)
arrange(X,desc(var1))
X$var4 <- rnorm(5)
X
Y <- cbind(X,rnorm(5))
Y
if(!file.exists("data")){dir.create("data")}
fileURL <- "https://data.baltimorecity.gov.api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL, destfile = "./data/baltimorerestaurants.csv", method = "curl")
dateDownloaded <- date()
dateDownloaded
restData <- read.csv("./data/baltimorerestaurants.csv", header = TRUE)
s1 <- seq(1,10,by=2) ; s1
s2 <- seq(1,10, len=3); s2
x <- c(1,3,8,25,100) ; seq(along = x)
library(reshape2)
head(mtcars)
mtcars$carname <- rownames(mtcars)
carMelt <- melt(mtcars, id=c("carname","gear","cyl"), measure.vars=c("mpg","hp"))
head(carMelt, n = 3)
cylData <- dcast(carMelt, cyl ~ variable)
cylData
cylData <- dcast(carMelt, cyl ~ variable, mean)
cylData
head(InsectSprays)
tapply(InsectSprays$count,InsectSprays$spray, sum)
agricultureLogical <- acs$ACR == 3 & acs$AGS == 6
ACS[which(agricultureLogical == TRUE),]
library(jpeg)
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileURL, destfile = "./data/jeff.jpeg", method = "curl")
dateDownloaded = date()
jeff <- readJPEG("./data/jeff.jpeg", native = TRUE)
quantile(jeff, probs = c(0.3,0.8))
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileURL, destfile = "./data/FGDP.csv", method = "curl")
FGDP <- read.csv("./data/FGDP.csv", header = TRUE, stringsAsFactors=FALSE)
head(FGDP)
str(FGDP)
FGDP <- FGDP[5:194,c(1,2,4,5)]
colnames(FGDP)[colnames(FGDP)=="X"] <- "countryCode"
colnames(FGDP)[colnames(FGDP)=="Gross.domestic.product.2012"] <- "gdpRank"
colnames(FGDP)[colnames(FGDP)=="X.2"] <- "countryName"
colnames(FGDP)[colnames(FGDP)=="X.3"] <- "gdpMillions"
FGDP$gdpRank <- as.numeric(FGDP$gdpRank)
str(FGDP)
fileURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileURL, destfile = "./data/Country.csv", method = "curl")
Country <- read.csv("./data/Country.csv", header = TRUE, stringsAsFactors=FALSE)
head(Country)
str(Country)
mergedData = merge(FGDP, Country, by.x="countryCode", by.y="CountryCode", all=FALSE)
head(mergedData)
summary(mergedData)
str(mergedData)
ordered <- mergedData[order(mergedData$gdpRank),]
# I lost a country somehow. St. Kitts is the 12th in my data.
ordered[178,]
sub(",","", mergedData$gdpMillions)
mergedData$gdpMillions <- sub(",","", mergedData$gdpMillions)
str(mergedData)
mergedData$gdpMillions <- as.numeric(mergedData$gdpMillions)
str(mergedData)
highincomeOECD <- subset(mergedData, mergedData$Income.Group == "High income: OECD")
mean(highincomeOECD$gdpRank)
highincomenonOECD <- subset(mergedData, mergedData$Income.Group == "High income: nonOECD")
mean(highincomenonOECD$gdpRank)
library(Hmisc)
GDPgroups = cut2(mergedData$gdpRank, g=5)
table(mergedData$Income.Group, GDPgroups)
cameras
names(cameras)
tolower(names(cameras))
splitNames = strsplit(names(cameras),"\\.")
splitNames[[5]]
splitNames[[6]]
splitNames[[6]][1]
firstElement <- function(x){x[1]}
sapply(splitNames, firstElement)
sub("_","",testName)
testName <- "this_is_a_test"
sub("_","",testName)
gsub("_","", testName)
grep("Alameda", cameras$intersection)
table(grepl("Alameda",cameras$intersection))
cameras2 <- cameras[!grepl("Alameda", cameras$intersection)]
cameras2 <- cameras[!grepl("Alameda", cameras$intersection),]
View(cameras2)
grep("Alameda", cameras$intersection, value=TRUE)
library(stringr)
nchar("Chris Elvin")
substr("Chris Elvin", 1,6)
substr("Chris Elvin", 1,5)
paste("Chris","Elvin")
paste0("Chris","Elvin")
str_trim("Chris      ")
d1 = date()
d1
class(d1)
d2 = Sys.Date()
class(d2)
format(d2, "%a, %b, %d)
format(d2, "%a, %b, %d")
d2 = Sys.Date()
class(d2)
format(d2, "%a, %b, %d")
format(d2, %A, %B, %D)
format(d2, %A, %B, %Y)
format(d2, %A, %B, %Y)
format(d2, %A, %B)
format(d2, "%A, %B, %D")
format(d2, "%A, %B, %Y")
format(d2, "%A %B %Y")
d1 = date()
d1
class(d1)
d2 = Sys.Date()
class(d2)
format(d2, "%a, %b, %d")
format(d2, "%A %B %Y")
format(d2, "%a, %b %d")
format(d2, "%A %B %Y")
x = c("1jan1960", "2jan1965", "23mar1920"); z = as.Date(x,"%d%m%Y")
z
x = c("1jan1960", "2jan1965", "23mar1920"); z = as.Date(x,"%d%b%Y")
z
z[1] - z[2]
as.numeric(z[1]-z[2])
weekdays(d2)
months(d2)
julian(d2)
library(lubridate)
install.packages(lubridate)
install.packages("lubridate")
library(lubridate); ymd("20140403")
mdy("04/02/2014")
dmy("04/03/2012")
View(acs)
strsplit(names(acs))
library(stringr)
strsplit(names(acs))
strsplit(acs$WGTP)
strsplit(acs$WGTP, split)
names(acs)
splitNames = strsplit(names(acs))
splitNames = strsplit(names(acs),)
splitNames = strsplit(names(acs),"\\.")
splitNames[[123]]
splitNames = strsplit(names(acs)," ")
splitNames[[123]]
splitNames = strsplit(names(acs),"wgtp")
splitNames[[123]]
sub(",","", mergedData$gdpMillions)
mergedData$gdpMillions <- sub(",","", mergedData$gdpMillions)
str(mergedData)
mergedData$gdpMillions <- as.numeric(mergedData$gdpMillions)
str(mergedData)
mean(mergedData$gdpMillions)
mean(mergedData$gdpMillions, na.rm = TRUE)
FGDP$gdpMillions <- sub(",","", FGDP$gdpMillions)
str(mergedData)
FGDPgdpMillions <- as.numeric(FGDP$gdpMillions)
str(mergedData)
mean(FGDP$gdpMillions, na.rm = TRUE)
FGDP$gdpMillions <- sub(",","", FGDP$gdpMillions)
str(mergedData)
FGDPgdpMillions <- as.numeric(FGDP$gdpMillions)
str(mergedData)
mean(FGDP$gdpMillions)
FGDP$gdpMillions <- sub(",","", FGDP$gdpMillions)
str(FGDP)
FGDPgdpMillions <- as.numeric(FGDP$gdpMillions)
str(mergedData)
View(FGDP)
mean(FGDP$gdpMillions)
View(FGDP)
mean(FGDP$gdpRANK)
mean(3,4,3)
mean(3,4,3,55)
FGDP$gdpMillions <- sub(",","", FGDP$gdpMillions)
str(FGDP)
FGDP$gdpMillions <- as.numeric(FGDP$gdpMillions)
str(mergedData)
mean(FGDP$gdpMillions)
splitNames[[6]][1]
firstElement <- function(x){x[1]}
sapply(splitNames, firstElement)
splitNames[[6]][1]
testName <- "this_is_a_test"
sub("_","",testName)
gsub("_","", testName)
grep("Alameda", cameras$intersection)
table(grepl("Alameda",cameras$intersection))
cameras2 <- cameras[!grepl("Alameda", cameras$intersection),]
cameras2
grep("Alameda", cameras$intersection, value=TRUE)
grep("^United", countryNames),3
grep("^United", countryNames)
grep("^United", acs)
grep("^United", acs),3
View(FGDP)
grep("^United", countryName)
grep("^United", FGDP$countryName)
grep("^United", FGDP$countryName),3
grep("^United", countryName),3
grep("^United", countryName)
grep("^United", FDGP$countryName)
grep("^United", FGDP$countryName)
grep("^United", FGDP$countryName),4
grep("^United", FGDP$countryName)
View(Country)
View(FGDP)
View(mergedData)
grep("June", mergedData)
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
grep("2012",sampleTimes)
len(grep("2012",sampleTimes))
sum(grep("2012",sampleTimes))
grep("Monday", sampleTimes)
sampleTimes = index(amzn)
sampleTimes
UCI <- read.table("./UCI HAR Dataset/test/X_test.txt")
setwd("~/Desktop")
UCI <- read.table("./UCI HAR Dataset/test/X_test.txt")
UCI
UCI
names(UCI)
UCI$V1
